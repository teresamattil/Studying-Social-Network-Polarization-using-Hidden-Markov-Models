{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a66e33-721b-43f2-b319-c4c837b6ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import math\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98077118-0eef-4410-b05c-a508d9b86958",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabfaaa-b0df-4325-b0fb-cd78000f7d54",
   "metadata": {},
   "source": [
    "## States and Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6aedbe-565d-414f-a066-1224c48367a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranges(true_conductances, num_states):\n",
    "    max_value = max(true_conductances.flatten())\n",
    "    min_value =  min(true_conductances.flatten())\n",
    "    ranges = [(x, y) for x, y in zip(np.linspace(min_value, max_value, num_states+1)[:-1], np.linspace(min_value, max_value, num_states+1)[1:])]\n",
    "    return ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36bbee49-6a46-4003-a89b-64fcd81e4715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_state_info(num_states, ranges, true_conductances, sampled_conductances):\n",
    "    states_info = {}\n",
    "    for i in range(num_states):\n",
    "        state_key = i\n",
    "        states_info[state_key] = {\n",
    "            'values': np.array([]),\n",
    "            'obs': np.array([]),\n",
    "            'diffs': np.array([])\n",
    "        }\n",
    "    \n",
    "    flattened_conductances = true_conductances.flatten()\n",
    "    flattened_sampled_conductances = sampled_conductances.flatten()\n",
    "    starts, ends = np.array(ranges).T\n",
    "    max_value = np.max(ends)\n",
    "    min_value = np.min(starts)\n",
    "\n",
    "    for t in range(np.size(sampled_conductances)): # for t in TxMC\n",
    "        if flattened_conductances[t] == min_value:\n",
    "            state_at_t = 0\n",
    "        elif flattened_conductances[t] == max_value:\n",
    "            state_at_t = num_states-1\n",
    "        else:\n",
    "            state_at_t = np.where((starts <= flattened_conductances[t]) & (flattened_conductances[t] < ends))[0][0]\n",
    "        states_info[state_at_t]['diffs'] = np.append( states_info[state_at_t]['diffs'] , flattened_sampled_conductances[t] - flattened_conductances[t])\n",
    "        states_info[state_at_t]['obs'] = np.append( states_info[state_at_t]['obs'] , flattened_sampled_conductances[t])\n",
    "        states_info[state_at_t]['values'] = np.append( states_info[state_at_t]['values'] , flattened_conductances[t])\n",
    "    return states_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d7b2b6a-600b-41dd-8e2d-545220068e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, shapiro, kstest\n",
    "\n",
    "def ecdf(data):\n",
    "    n = len(data)\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return x, y\n",
    "\n",
    "def prove_gaussian_noise(num_states, states_info, scenario, measure, ratio):\n",
    "    means = []\n",
    "    stds = []\n",
    "    p_values = np.zeros(num_states)\n",
    "    states = []\n",
    "\n",
    "    num_cols = int(np.ceil(np.sqrt(num_states)))\n",
    "    num_rows = int(np.ceil(num_states / num_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "    axes = axes.flatten() \n",
    "\n",
    "    for i in range(num_states):\n",
    "        data = states_info[i]['obs']\n",
    "        mean = np.mean(data)\n",
    "        std_dev = np.std(data)\n",
    "        x_ecdf, y_ecdf = ecdf(data)\n",
    "        \n",
    "        standarized_data = (data - mean) / std_dev\n",
    "        stat, p_value = shapiro(standarized_data)\n",
    "        stat_ks, p_value_ks = kstest(standarized_data, 'norm')\n",
    "        p_values[i] = p_value\n",
    "\n",
    "        x = np.linspace(mean - 3 * std_dev, mean + 3 * std_dev, 1000)\n",
    "        cdf = norm.cdf(x, loc=mean, scale=std_dev)\n",
    "        \n",
    "        states.append(np.mean(states_info[i]['values']))\n",
    "        means.append(np.mean(states_info[i]['obs']))\n",
    "        stds.append(np.std(states_info[i]['obs']))\n",
    "\n",
    "        #print(measure,\",\", scenario,\",\", ratio, \",\", i, \",\",p_value_ks,\",\",  p_value>0.05)\n",
    "\n",
    "        axes[i].plot(x_ecdf, y_ecdf, marker='.', linestyle='none', color='blue', label='ECDF')\n",
    "        axes[i].plot(x, cdf, color='red', label='Theoretical Normal CDF')\n",
    "        axes[i].set_xlabel('Data')\n",
    "        axes[i].set_ylabel(f'shap p-value: {p_value:.3f}')\n",
    "        axes[i].set_title(f'State {i+1} ks p: {round(p_value_ks,3)}')\n",
    "        axes[i].grid(True)\n",
    "        axes[i].legend()\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    plt.suptitle(f'cdf {measure} ratio {ratio}')\n",
    "    plt.tight_layout()\n",
    "    #fig.savefig(f'{scenario}/cdfs_{measure}/cdfs_ratio{int(ratio*10)}/cdf2_{num_states}_states', dpi=300) \n",
    "    #plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return means, stds, states "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec7ee6-41e0-4a39-8e89-8c230e74f83b",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e282764f-d72a-483e-b3f1-7b014471986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def trainP(num_states, ranges, true_conductances):\n",
    "    n = num_states\n",
    "    max_value = np.max(true_conductances)\n",
    "    min_value = np.min(true_conductances)\n",
    "    # Sample data: sequences of observed states\n",
    "    data = np.zeros((true_conductances.shape[0],true_conductances.shape[1]))\n",
    "    \n",
    "    starts, ends = np.array(ranges).T\n",
    "    for i in range(true_conductances.shape[0]):\n",
    "        for j in range(true_conductances.shape[1]):\n",
    "            if true_conductances[i,j] == max_value:\n",
    "                data[i, j] = 0\n",
    "            elif true_conductances[i,j] == min_value:\n",
    "                data[i, j] = num_states-1\n",
    "            else:\n",
    "                data[i, j] = np.where((starts <= true_conductances[i,j]) & (true_conductances[i,j] < ends))[0][0]\n",
    "    P = np.zeros((n, n))\n",
    "    initial_state_count = np.zeros(n)\n",
    "    \n",
    "    # Count transitions\n",
    "    for sequence in data:\n",
    "        initial_state = int(sequence[0])\n",
    "        initial_state_count[initial_state] += 1\n",
    "        for i in range(len(sequence) - 1):\n",
    "            current_state = int(sequence[i])\n",
    "            next_state = int(sequence[i + 1])\n",
    "            P[current_state, next_state] += 1\n",
    "    \n",
    "    # Convert counts to probabilities\n",
    "    pi0 = initial_state_count / initial_state_count.sum()\n",
    "    for i in range(n):\n",
    "        P[i, :] /= P[i, :].sum()\n",
    "\n",
    "    return P, pi0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1ad79d-bc09-450a-bb43-2840560ced31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBtransition(A, T, t, k):\n",
    "    m = len(A)\n",
    "    n = len(A[0])\n",
    "    B = np.zeros((m, n))\n",
    "    A1 = np.linalg.matrix_power(A, T - t - 1)\n",
    "    A2 = np.linalg.matrix_power(A, T - t)\n",
    "    if t==T-1:\n",
    "        return np.eye(m)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if A1[j, k]==0 or A[i, j]==0:\n",
    "                B[i, j] = 0\n",
    "            else:\n",
    "                B[i, j] = A[i, j] * A1[j, k] / A2[i, k]\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdec755-4b4e-4756-835f-e11acf4dfdc4",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af9d631d-af0f-49f4-9340-898ff44c42e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def hmm_filter(P, pi0, cond, cond_sampled, states, gaussian_parameters):\n",
    "    q_hmm = []\n",
    "    t = 0\n",
    "    state_estimates_hmm = []\n",
    "    \n",
    "    O = np.diag([ norm.pdf(cond_sampled[0],gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "    \n",
    "    numerator = O @ P.T @ (pi0).T\n",
    "    denominator = np.sum(O @ P.T @ (pi0).T)\n",
    "    qt = numerator / denominator\n",
    "    q_hmm.append(qt)\n",
    "    real_state = cond[t]\n",
    "    estimated_state = states[np.argmax(qt)]\n",
    "    state_estimates_hmm.append(estimated_state)\n",
    "\n",
    "    error_hmm = np.zeros(T)\n",
    "    error_hmm[0] = (estimated_state-real_state)\n",
    "    #print(\"t: \",t, \"obs:\", cond_sampled[0], \"estimated\", np.round(estimated_state,3), \"real one\", real_state, \"error:\", error_hmm[t]**2)\n",
    "        \n",
    "    t +=1\n",
    "    \n",
    "    for obs in cond_sampled[1:]:\n",
    "        #O = np.diag([ norm.pdf(obs-states[i], gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "        O = np.diag([ norm.pdf(obs, gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "        numerator = O @ P.T @ q_hmm[t-1]\n",
    "        denominator = np.sum(O @ P.T @ q_hmm[t-1])\n",
    "        qt = numerator / denominator\n",
    "        \n",
    "        estimated_state = states[np.argmax(qt)]\n",
    "        real_state = cond[t]\n",
    "        error_hmm[t] = (estimated_state-real_state) \n",
    "    \n",
    "        q_hmm.append(qt)\n",
    "        state_estimates_hmm.append(estimated_state)\n",
    "        #print(\"t: \",t, \"obs:\", obs, \"estimated\", np.round(estimated_state,3), \"real one\", real_state, \"error:\", error_hmm[t]**2)\n",
    "        t+=1\n",
    "    \n",
    "    hmm_squared_errors = error_hmm** 2\n",
    "    return hmm_squared_errors, q_hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45591cad-8841-4eee-abc8-9363d93c8ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def hmb_filter(Bt, pi0, cond, cond_sampled, states,gaussian_parameters):\n",
    "    q_hmb = []\n",
    "    t = 0\n",
    "    state_estimates_hmb = []\n",
    "    \n",
    "    O = np.diag([ norm.pdf(cond_sampled[0],gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "    numerator = O @ (Bt[t]).T @ (pi0).T\n",
    "    denominator = np.sum(O @ (Bt[t]).T @ (pi0 ).T)\n",
    "    qt = numerator / denominator\n",
    "    q_hmb.append(qt)\n",
    "    real_state = cond[t]\n",
    "    estimated_state = states[np.argmax(qt)]\n",
    "    state_estimates_hmb.append(estimated_state)\n",
    "\n",
    "    error_hmb = np.zeros(T)\n",
    "    error_hmb[0] = (estimated_state-real_state)\n",
    "    #print(\"t: \",t, \"obs:\", cond_sampled[0], \"estimated\", np.round(estimated_state,3), \"real one\", real_state, \"error:\", error_hmb[t]**2)\n",
    "        \n",
    "    t +=1\n",
    "    for obs in cond_sampled[1:]:\n",
    "        #O = np.diag([ norm.pdf(obs-states[i], gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "        O = np.diag([ norm.pdf(obs, gaussian_parameters[i, 0], gaussian_parameters[i, 1]) for i in range(num_states)] )\n",
    "        numerator = O @ (Bt[t]).T @ q_hmb[t-1]\n",
    "        denominator = np.sum(O @ (Bt[t]).T @ q_hmb[t-1])\n",
    "        qt = numerator / denominator\n",
    "    \n",
    "        \"\"\"\n",
    "        weight_average = qt * states\n",
    "        idx = np.argmin(np.abs(weight_average - np.sum(states)))\n",
    "        estimated_state = states[idx]\n",
    "        \"\"\"\n",
    "        estimated_state = states[np.argmax(qt)]\n",
    "        real_state = cond[t]\n",
    "        error_hmb[t] = (estimated_state-real_state)\n",
    "        \n",
    "        q_hmb.append(qt)\n",
    "        state_estimates_hmb.append(estimated_state)\n",
    "        \n",
    "        #print(\"t: \",t, \"obs:\", obs, \"estimated\", np.round(estimated_state,3), \"real one\", real_state, \"error:\", error_hmb[t]**2)\n",
    "        t+=1\n",
    "    \n",
    "    hmb_squared_errors = error_hmb ** 2\n",
    "    return hmb_squared_errors, q_hmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d38f4de-5734-44c4-b4bd-14e3ed028924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_x_to_txt(xs, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for x in xs:\n",
    "            file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65797df7-ac47-430e-ade2-11d1cbe29289",
   "metadata": {},
   "source": [
    "# Simulation and measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e652e6e-4fa8-4a85-abf5-4368edc60c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def polarization_score_sampled(G, ratio):\n",
    "  num_edges = G.number_of_edges()\n",
    "  sample_size = math.floor(ratio*num_edges)\n",
    "\n",
    "  # Sampling the edges and copying the nodes attributes\n",
    "  random_sample_edges = random.sample(list(G.edges), sample_size)\n",
    "  G_sample = nx.Graph()\n",
    "  G_sample.add_edges_from(random_sample_edges)\n",
    "  for node in G_sample.nodes():\n",
    "    G_sample.nodes[node]['opinion'] = G.nodes[node]['opinion']\n",
    "    \n",
    "  intraideological_conn = 0\n",
    "  cross_ideological_conn = 0\n",
    "  for u, v in G_sample.edges():\n",
    "    if G_sample.nodes[u]['opinion'] * G_sample.nodes[v]['opinion'] > 0:\n",
    "      intraideological_conn += 1\n",
    "    else: \n",
    "      cross_ideological_conn +=1\n",
    "      #print(\"u: \", G.nodes[u]['opinion'], \"v: \",G.nodes[v]['opinion'])\n",
    "  pol_score = abs(intraideological_conn-cross_ideological_conn) / (intraideological_conn+cross_ideological_conn)  \n",
    "  \n",
    "  return pol_score\n",
    "\n",
    "def polarization_score(G):\n",
    "  intraideological_conn = 0\n",
    "  cross_ideological_conn = 0\n",
    "  for u, v in G.edges():\n",
    "    if G.nodes[u]['opinion']*G.nodes[v]['opinion'] >0:\n",
    "      intraideological_conn += 1\n",
    "    else: \n",
    "      cross_ideological_conn +=1\n",
    "      #print(\"u: \", G.nodes[u]['opinion'], \"v: \",G.nodes[v]['opinion'])\n",
    "  pol_score = abs(intraideological_conn-cross_ideological_conn) / (intraideological_conn+cross_ideological_conn)  \n",
    "  \n",
    "  return pol_score\n",
    "\n",
    "def algebraic_connectivity(graph):\n",
    "  conn = nx.algebraic_connectivity(graph, weight ='weight')\n",
    "  return conn\n",
    "\n",
    "def sampled_algebraic_connectivity(graph, ratio):\n",
    "  num_edges = graph.number_of_edges()\n",
    "  sample_size = math.floor(ratio*num_edges)\n",
    "\n",
    "  random_sample_edges = random.sample(list(graph.edges), sample_size)\n",
    "  G_sample = nx.Graph()\n",
    "  G_sample.add_edges_from(random_sample_edges)\n",
    "  #print(\"Sampled graph: \", G_sample)\n",
    "  conn = nx.algebraic_connectivity(G_sample, weight ='weight')\n",
    "\n",
    "  return conn\n",
    "\n",
    "def bimodality_coefficient(graph):\n",
    "    opinions = np.array([graph.nodes[node]['opinion'] for node in graph.nodes()])\n",
    "    mean_opinion = np.mean(opinions)\n",
    "    skewness = ((opinions - mean_opinion)**3).mean() / ((opinions - mean_opinion)**2).mean()**(3/2)\n",
    "    kurtosis = ((opinions - mean_opinion)**4).mean() / ((opinions - mean_opinion)**2).mean()**2\n",
    "    bimodality_coeff = (skewness**2 + 1) / kurtosis\n",
    "    return bimodality_coeff\n",
    "\n",
    "def sampled_bimodality_coefficient(graph, ratio):\n",
    "    num_edges = graph.number_of_edges()\n",
    "    sample_size = math.floor(ratio*num_edges)\n",
    "    \n",
    "    random_sample_edges = random.sample(list(graph.edges), sample_size)\n",
    "    G_sample = nx.Graph()\n",
    "    G_sample.add_edges_from(random_sample_edges)\n",
    "    for node in G_sample.nodes():\n",
    "        G_sample.nodes[node]['opinion'] = graph.nodes[node]['opinion']\n",
    "    \n",
    "    opinions = np.array([G_sample.nodes[node]['opinion'] for node in G_sample.nodes()])\n",
    "    mean_opinion = np.mean(opinions)\n",
    "    skewness = ((opinions - mean_opinion)**3).mean() / ((opinions - mean_opinion)**2).mean()**(3/2)\n",
    "    kurtosis = ((opinions - mean_opinion)**4).mean() / ((opinions - mean_opinion)**2).mean()**2\n",
    "    bimodality_coeff = (skewness**2 + 1) / kurtosis\n",
    "    return bimodality_coeff\n",
    "\n",
    "def balance(graph):\n",
    "  c1 = 0\n",
    "  c2 = 0\n",
    "\n",
    "  for node in list(graph.nodes()):\n",
    "    if graph.nodes[node]['opinion'] < 0:\n",
    "      c1 += 1\n",
    "    else: \n",
    "      c2 +=1\n",
    "      #print(\"u: \", G.nodes[u]['opinion'], \"v: \",G.nodes[v]['opinion'])\n",
    "  pol_score = min(c1,c2) / max(c1,c2)\n",
    "  \n",
    "  return pol_score\n",
    "\n",
    "def sampled_balance(graph,ratio):\n",
    "    num_edges = graph.number_of_edges()\n",
    "    sample_size = math.floor(ratio*num_edges)\n",
    "\n",
    "    # Sampling the edges and copying the nodes attributes\n",
    "    random_sample_edges = random.sample(list(graph.edges), sample_size)\n",
    "    G_sample = nx.Graph()\n",
    "    G_sample.add_edges_from(random_sample_edges)\n",
    "    for node in G_sample.nodes():\n",
    "        G_sample.nodes[node]['opinion'] = graph.nodes[node]['opinion']\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "\n",
    "    for node in list(G_sample.nodes()):\n",
    "        if G_sample.nodes[node]['opinion'] < 0:\n",
    "          c1 += 1\n",
    "        else: \n",
    "          c2 +=1\n",
    "          #print(\"u: \", G.nodes[u]['opinion'], \"v: \",G.nodes[v]['opinion'])\n",
    "    pol_score = min(c1,c2) / max(c1,c2)\n",
    "    return pol_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1fde081-cb30-473b-a1ba-d2dbdf8e9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def initialize_agents(G, d1):\n",
    "    # Initialize agent attributes within the graph\n",
    "    nx.set_node_attributes(G, {i: {'opinion': random.uniform(-1, 1),\n",
    "                                   'state': 'Uninformed',\n",
    "                                   'exposure': 0,\n",
    "                                   'hostility': 0,\n",
    "                                   'd1': random.uniform(d1[0], d1[1]),\n",
    "                                   'd2': 0.1,\n",
    "                                   'mu': 0.1} for i in G.nodes()})\n",
    "\n",
    "def propagate_opinions(G, phi, pd_function, pt_function, prewire_function, num_rewire):\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes)  # Randomize node order to simulate asynchronous updating\n",
    "\n",
    "    edges_to_remove = []\n",
    "    edges_to_add = []\n",
    "\n",
    "    for node in nodes:\n",
    "        h = f_sentiment_both_sided_extreme()  # Assume this generates a new post sentiment\n",
    "        if np.random.random() < pt_function(abs(h - G.nodes[node]['opinion'])):\n",
    "            for neighbor in list(G.neighbors(node)):\n",
    "                opinion_diff = abs(G.nodes[node]['opinion'] - G.nodes[neighbor]['opinion'])\n",
    "                if np.random.random() < pd_function(opinion_diff, phi):\n",
    "                    attraction_prob = 1 - abs(h- G.nodes[neighbor]['opinion'])\n",
    "                    # Attraction or repulsion decision\n",
    "                    if np.random.random() < attraction_prob:\n",
    "                        G.nodes[neighbor]['opinion'] += np.sign(G.nodes[node]['opinion'] - G.nodes[neighbor]['opinion']) * 0.1\n",
    "                        if G.nodes[neighbor]['opinion'] >1:\n",
    "                            G.nodes[neighbor]['opinion'] =1\n",
    "                        elif G.nodes[neighbor]['opinion'] <-1:\n",
    "                            G.nodes[neighbor]['opinion']  =-1\n",
    "                    else:\n",
    "                        G.nodes[neighbor]['opinion'] -= np.sign(G.nodes[node]['opinion'] - G.nodes[neighbor]['opinion']) * 0.1\n",
    "                        if G.nodes[neighbor]['opinion'] >1:\n",
    "                            G.nodes[neighbor]['opinion'] =1\n",
    "                        elif G.nodes[neighbor]['opinion'] <-1:\n",
    "                            G.nodes[neighbor]['opinion']  =-1\n",
    "                        if opinion_diff > 0.5 and np.random.random() < prewire_function(opinion_diff):\n",
    "                            edges_to_remove.append((node, neighbor))\n",
    "\n",
    "    # Apply all rewiring and edge modifications after all nodes have been processed\n",
    "    \n",
    "    for (node, neighbor) in edges_to_remove:\n",
    "        if G.has_edge(node, neighbor):\n",
    "            G.remove_edge(node, neighbor)\n",
    "            \n",
    "            # Collect potential new neighbors from the neighbors of the node's neighbors\n",
    "            potential_new_neighbors = set()\n",
    "            for n in G.neighbors(node):\n",
    "                if n != neighbor:  # Exclude the neighbor being removed\n",
    "                    potential_new_neighbors.update(G.neighbors(n))\n",
    "            \n",
    "            # Remove the current node and its existing neighbors from the potential new neighbors\n",
    "            potential_new_neighbors.discard(node)\n",
    "            potential_new_neighbors.difference_update(set(G.neighbors(node)))\n",
    "            \n",
    "            # Convert to list to use random.choice\n",
    "            potential_new_neighbors = list(potential_new_neighbors)\n",
    "            \n",
    "            if potential_new_neighbors:\n",
    "                for i in range( int(np.random.uniform(0,num_rewire))):\n",
    "                    new_neighbor = random.choice(potential_new_neighbors)\n",
    "                    edges_to_add.append((node, new_neighbor))\n",
    "                    \n",
    "    #print(edges_to_add)\n",
    "    for (node, new_neighbor) in edges_to_add:\n",
    "        if not G.has_edge(node, new_neighbor):\n",
    "            G.add_edge(node, new_neighbor)\n",
    "    \n",
    "\n",
    "def simulate_network(N, m, T, phi, pd_function, pt_function, prewire_function, num_rewire):\n",
    "    G = nx.barabasi_albert_graph(N, m)\n",
    "    initialize_agents(G, [0.1, 1.0])  # Assuming some range for d1\n",
    "    results = [G.copy()]\n",
    "    for _ in range(T-1):\n",
    "        propagate_opinions(G, phi,pd_function, pt_function, prewire_function, num_rewire)\n",
    "        results.append(G.copy())\n",
    "    return results\n",
    "\n",
    "# Define probability functions\n",
    "def Pt_pol(x):\n",
    "    return np.cos(x * np.pi / 2) ** 2\n",
    "def Pt_sim(x):\n",
    "    return np.cos(x * np.pi / 2) ** 2 if x <= 1 else 0\n",
    "def Pt_uni(x):\n",
    "    return 1\n",
    "def Pt_all(x):\n",
    "    random = np.random.uniform(0,1)\n",
    "    if random <0.333:\n",
    "        return Pt_pol(x)\n",
    "    elif random <0.666:\n",
    "        return Pt_sim(x)\n",
    "    else:\n",
    "        return Pt_uni(x)\n",
    "    \n",
    "def PdI(y, phi):\n",
    "    return np.cos(y * np.pi / 2 + phi) ** 2\n",
    "def PdII(y, phi):\n",
    "    return np.cos(y * np.pi / 4 + phi) ** 2\n",
    "def PdIII(y, phi):\n",
    "    return 1\n",
    "    \n",
    "def Prewire(y):\n",
    "    return np.cos(y * np.pi / 2) ** 2 if y > 1 else 0\n",
    "\n",
    "def f_sentiment_both_sided_extreme():\n",
    "    coin = random.uniform(0, 1)\n",
    "    if coin > 0.5:\n",
    "        return random.uniform(0.9, 1)\n",
    "    else:\n",
    "        return  random.uniform(-1, -0.9)\n",
    "\n",
    "def f_sentiment_random():\n",
    "    return random.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b73ba-778e-452f-a362-04871956eca4",
   "metadata": {},
   "source": [
    "# Get train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e30549-bd8e-41d9-bd9e-fb93d6ad15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker2(N, m, T, phi, ratio, Pd,  Pt, Prewire, num_rewire):\n",
    "    graphs = simulate_network(N, m, T, phi, Pd,  Pt, Prewire, num_rewire)\n",
    "    true_conductances = [polarization_score(g) for g in graphs]\n",
    "    samp_conductances = [polarization_score_sampled(g, ratio) for g in graphs]\n",
    "    return (true_conductances, samp_conductances)\n",
    "def simulate_rewiring_wrapper2(args):\n",
    "    return worker2(*args)\n",
    "\n",
    "# -------------------------------------\n",
    "# PARAMETERS\n",
    "# Change the measure in worker function too\n",
    "\"\"\"\n",
    "polarization_score\n",
    "polarization_score_sampled\n",
    "\n",
    "bimodality_coefficient\n",
    "sampled_bimodality_coefficient\n",
    "\"\"\"\n",
    "\n",
    "measures = ['pol_scores', 'bc']\n",
    "measure = 'pol_scores'\n",
    "measure_used = 'Homophily' # Title\n",
    "\n",
    "pol_measure = polarization_score\n",
    "sampled_pol_measure = polarization_score_sampled\n",
    "num_simulations = 10\n",
    "MC = 200\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e36af9-1b45-4c32-b013-9a6e3fce5704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define titles for each subplot\n",
    "\n",
    "\"\"\"\n",
    "I-   PdI ; Pt_pol,and phi= 0:49,\n",
    "II-  PdI ; Pt_uni, and phi= 2.65,\n",
    "III- PdII, PtUni, and phi= 0\n",
    "IV-  PdII; Ptuni, and phi= 1:47,\n",
    "V-   PdI ; Ptpol, and phi= 0, \n",
    "-VI- PdI ; Pt_sim, and phi= 1:47, \n",
    "VII- PdII; Ptsim, and phi= 0\n",
    "VIII-PdII; Ptsim, and phi= 1.47\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "titles = ['I- PdI ; Pt_pol , phi=0:49,]',\n",
    "          'II- PdI ; Ptuni , and phi= 2.65,',\n",
    "          'III- PdII, PtUni, phi=0',\n",
    "          'IV- PdII;Ptuni, and phi 1:47,',\n",
    "          'V- PdI ;Ptpol, and phi=0',\n",
    "          'VI- PdI ;Ptsim, and phi= 1:47, ',\n",
    "          'VII- PdII;Ptsim, and phi 0',\n",
    "          'VIII- PdII;Ptall, and phi= 1.47'\n",
    "         ]\n",
    "\n",
    "\n",
    "N=500\n",
    "MC = 200\n",
    "m = 9\n",
    "T = 30\n",
    "\n",
    "prewire_function = lambda y: Prewire(y)  # Standard rewiring based on strong disagreement\n",
    "num_rewire = 3\n",
    "\n",
    "ratios = [0.01, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "scenarios = ['scenario_I',\n",
    "             'scenario_II',\n",
    "             'scenario_III',\n",
    "             'scenario_IV',\n",
    "             'scenario_V',\n",
    "             'scenario_VI',\n",
    "             'scenario_VII',\n",
    "             'scenario_VIII']\n",
    "\n",
    "\n",
    "Pd_functions = [PdI, PdI, PdII, PdII, PdI, PdI, PdII, PdII]\n",
    "Pt_functions = [Pt_pol,Pt_uni,Pt_uni,Pt_uni, Pt_pol,Pt_sim,Pt_sim, Pt_sim]\n",
    "phis = [0.49, 2.65, 0, 1.47, 0, 1.47, 0, 1.47]\n",
    "\n",
    "\n",
    "print(\"Measure: \", measure)\n",
    "for ratio in np.flip(ratios):\n",
    "    print(f\"----------------- Processing ratio {ratio}----------------- \")\n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        # Generate opinions for the current scenario\n",
    "        scenario = scenarios[i]\n",
    "        print(f\"Processing scenario {i+1}\")\n",
    "        Pd = Pd_functions[i]\n",
    "        Pt = Pt_functions[i]\n",
    "        phi = phis[i]\n",
    "\n",
    "        args_list = [(N, m, T, phi, ratio, Pd,  Pt, Prewire, num_rewire) for _ in range(MC)]\n",
    "        with mp.Pool() as pool:\n",
    "            results = pool.map(simulate_rewiring_wrapper2, args_list)\n",
    "        list_of_tuples = results\n",
    "        true_conductances_test, sampled_conductances_test = zip(*results)\n",
    "\n",
    "        # Writing training data\n",
    "        print(\"training data\")\n",
    "        write_x_to_txt(true_conductances.flatten(), f'{scenario}/{measure}_ratio{int(ratio*10)}.dat')\n",
    "        write_x_to_txt(sampled_conductances.flatten(), f'{scenario}/{measure}_sampled_ratio{int(ratio*10)}.dat')\n",
    "        \n",
    "        # saving plot of training data\n",
    "        n_rows, n_cols = true_conductances.shape\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        offset = 0.1\n",
    "        for col in range(n_cols):\n",
    "            x1 = np.full(n_rows, col + 1 - offset)  # Slightly left\n",
    "            y1 = true_conductances[:, col]\n",
    "            plt.scatter(x1, y1, color='red', alpha=0.6, label='true_conductances' if col == 0 else \"\")\n",
    "\n",
    "            x2 = np.full(n_rows, col + 1 + offset)  # Slightly right\n",
    "            y2 = sampled_conductances[:, col]\n",
    "            plt.scatter(x2, y2, color='grey', alpha=0.6, label='sampled_conductances' if col == 0 else \"\")\n",
    "        plt.xlabel('t')\n",
    "        plt.title('Scatter Plot of Sampled vs True conductances')\n",
    "        plt.xticks(range(1, n_cols + 1))  # Set x-ticks to match column numbers\n",
    "        plt.yticks(np.linspace(0,1,11)) \n",
    "        plt.legend(fontsize=14)\n",
    "        plt.savefig(f'{scenario}/scatter {measure} plot_ratio{int(ratio*10)}', dpi=300) \n",
    "        plt.clf()\n",
    "\n",
    "        meaned_conductances = np.mean(true_conductances, axis=0)\n",
    "        meaned_sampled_conductances = np.mean(sampled_conductances, axis=0)\n",
    "        # Plot graph conductances\n",
    "        t = np.linspace(0,T,len(meaned_conductances))\n",
    "        plt.plot(t, meaned_conductances, label='Real conductances')\n",
    "        plt.plot(t, meaned_sampled_conductances, label='Sampled conductances')\n",
    "        title = f\"Graph conduc with {measure} N={N} nodes and ratio {ratio}\"\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Simulation Iteration\")\n",
    "        plt.ylabel(\"Polarization Score\")\n",
    "        plt.legend(fontsize=14)\n",
    "        #plt.show()\n",
    "        plt.savefig(f'{scenario}/mean {measure} trajectory ratio{int(ratio*10)}', dpi=300) \n",
    "        plt.clf()\n",
    "\n",
    "        # Test Data\n",
    "        graphs = simulate_network(N, m, T, phi, Pd, Pt, Prewire, num_rewire)\n",
    "        cond = np.array([pol_measure(g) for g in graphs])\n",
    "        cond_sampled= np.array([sampled_pol_measure(g, ratio) for g in graphs])\n",
    "\n",
    "        write_x_to_txt(cond_sampled.flatten(), f'{scenario}/test_{measure}_sampled_test_ratio{int(ratio*10)}.dat')\n",
    "        write_x_to_txt(cond.flatten(), f'{scenario}/test_{measure}_test_ratio{int(ratio*10)}.dat')\n",
    "\n",
    "        plt.plot(cond, label=\"true\")\n",
    "        plt.plot(cond_sampled, label=\"sampled\")\n",
    "        for i in range(T):\n",
    "            plt.axvline(x=i, color='gray', linestyle='--', linewidth=0.5)  # Adjust color, linestyle, and linewidth as needed\n",
    "        \n",
    "        plt.legend(fontsize=14)\n",
    "        plt.title(f'{scenario} test data {measure} ratio {ratio}')\n",
    "        plt.savefig(f'{scenario}/test_{measure}_ratio{int(ratio*10)}', dpi=300) \n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88dbb4-3eed-4673-a6b3-09a5c4189f11",
   "metadata": {},
   "source": [
    "# Compare per scenario multiple tests each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a37a3-e724-433b-a6fb-c04427928894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#------------------------------------------------------------\n",
    "measure = 'pol_scores'\n",
    "measure_used = 'Homophily' # Title\n",
    "#------------------------------------------------------------\n",
    "# Fixed parameters\n",
    "N = 500\n",
    "m = 9\n",
    "T = 30\n",
    "num_rewire = 3\n",
    "#------------------------------------------------------------\n",
    "\n",
    "scenarios = [\n",
    "    'scenario_I', 'scenario_II', 'scenario_III', 'scenario_IV',\n",
    "    'scenario_V', 'scenario_VI', 'scenario_VII', 'scenario_VIII'\n",
    "]\n",
    "titles = [\n",
    "    'Scenario I',\n",
    "    'Scenario II',\n",
    "    'Scenario III',\n",
    "    'Scenario IV',\n",
    "    'Scenario V',\n",
    "    'Scenario VI',\n",
    "    'Scenario VII',\n",
    "    'Scenario VIII'\n",
    "]\n",
    "Pd_functions = [PdI, PdI, PdII, PdII, PdI, PdI, PdII, PdII]\n",
    "Pt_functions = [Pt_pol, Pt_uni, Pt_uni, Pt_uni, Pt_pol, Pt_sim, Pt_sim, Pt_all]\n",
    "phis = [0.49, 2.65, 0, 1.47, 0, 1.47, 0, 1.47]\n",
    "ratios = [0.01, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "print(measure)\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    print(\"-------------- scenario: \", scenario, \"--------------\")\n",
    "    num_plots = len(ratios)\n",
    "    num_cols = 2\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 16))\n",
    "    axes = axes.flatten()\n",
    "    for index, ratio in enumerate(ratios):\n",
    "        mse_hmbs = []\n",
    "        mse_hmms = []\n",
    "        print(ratio)\n",
    "        with open(f'{scenario}/{measure}_ratio{int(ratio*10)}.dat', 'r') as input_file:\n",
    "            lines = input_file.readlines()\n",
    "        read_true_cond = np.array([line.strip().split() for line in lines]).astype(float)\n",
    "        true_conductances = (read_true_cond[:]).reshape(MC, T)\n",
    "        \n",
    "        with open(f'{scenario}/{measure}_sampled_ratio{int(ratio*10)}.dat', 'r') as input_file:\n",
    "            lines = input_file.readlines()\n",
    "        read_sampl_cond = np.array([line.strip().split() for line in lines]).astype(float)\n",
    "        sampled_conductances = (read_sampl_cond[:]).reshape(MC, T)\n",
    "        \n",
    "        for sim in range(num_simulations):\n",
    "            print(\"sim\", sim)\n",
    "            with open(f'{scenario}/test_{measure}_test{sim}_ratio{int(ratio*10)}.dat', 'r') as input_file:\n",
    "                lines = input_file.readlines()\n",
    "            cond = np.array([line.strip().split() for line in lines]).astype(float).flatten()\n",
    "\n",
    "            with open(f'{scenario}/test_{measure}_sampled_test{sim}_ratio{int(ratio*10)}.dat', 'r') as input_file:\n",
    "                lines = input_file.readlines()\n",
    "            cond_sampled = np.array([line.strip().split() for line in lines]).astype(float).flatten()\n",
    "\n",
    "            min_state = 4\n",
    "            max_state = 15\n",
    "\n",
    "            mse_hmbs2 = []\n",
    "            mse_hmms2 = []\n",
    "\n",
    "            for num_states in range(min_state, max_state + 1):\n",
    "                ranges = create_ranges(true_conductances, num_states)\n",
    "                state_info = create_state_info(num_states, ranges, true_conductances, sampled_conductances)\n",
    "                is_any_empty = any(len(state_info[state]['values']) < 3 for state in state_info)\n",
    "                if not is_any_empty:\n",
    "                    means, stds, states = prove_gaussian_noise(num_states, state_info, scenario, measure, ratio)\n",
    "                    P, pi0 = trainP(num_states, ranges, true_conductances)\n",
    "                    gaussian_parameters = np.column_stack((means, stds))\n",
    "\n",
    "                    final_state = (np.abs(states - np.mean(true_conductances[:, -1]))).argmin()\n",
    "\n",
    "                    Bt = [MBtransition(P, T, t, final_state) for t in range(T)]\n",
    "                    hmm_squared_errors, q_hmm = hmm_filter(P, pi0, cond, cond_sampled, states, gaussian_parameters)\n",
    "                    hmb_squared_errors, q_hmb = hmb_filter(Bt, pi0, cond, cond_sampled, states, gaussian_parameters)\n",
    "\n",
    "                    mse_hmb2 = np.mean(hmb_squared_errors)\n",
    "                    mse_hmm2 = np.mean(hmm_squared_errors)\n",
    "                    mse_hmbs2.append(mse_hmb2)\n",
    "                    mse_hmms2.append(mse_hmm2)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            mse_hmbs.append(mse_hmbs2)\n",
    "            mse_hmms.append(mse_hmms2)\n",
    "\n",
    "        mean_mse_hmb = np.mean(mse_hmbs, axis=0)\n",
    "        mean_mse_hmm = np.mean(mse_hmms, axis=0)\n",
    "\n",
    "        ax = axes[index]\n",
    "        states_studied = np.linspace(min_state, max_state, max_state - min_state + 1)[0:len(mean_mse_hmb)]\n",
    "        ax.plot(states_studied, mean_mse_hmb, label=\"HMB\")\n",
    "        ax.plot(states_studied, mean_mse_hmm, label=\"HMM\")\n",
    "        ax.set_ylabel(\"MSE\", fontsize=16)\n",
    "        ax.set_title(f'MSE {titles[i]} ratio {ratio}', fontsize=23)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.legend(fontsize=17)\n",
    "\n",
    "    plt.suptitle(f'{measure_used} Mean Squared Error {titles[i]} per ratio', fontsize=30)\n",
    "    plt.savefig(f'{scenario}_MSE_overview_{measure}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ddb2a-6d45-45f4-913b-972e906d2cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10",
   "language": "python",
   "name": "py3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
